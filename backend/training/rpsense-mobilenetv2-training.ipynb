{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-07-07T13:28:38.316973Z",
     "iopub.status.busy": "2025-07-07T13:28:38.316715Z",
     "iopub.status.idle": "2025-07-07T13:29:21.293058Z",
     "shell.execute_reply": "2025-07-07T13:29:21.292386Z",
     "shell.execute_reply.started": "2025-07-07T13:28:38.316951Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T11:14:11.643438Z",
     "iopub.status.busy": "2025-07-07T11:14:11.642930Z",
     "iopub.status.idle": "2025-07-07T11:14:15.620180Z",
     "shell.execute_reply": "2025-07-07T11:14:15.619434Z",
     "shell.execute_reply.started": "2025-07-07T11:14:11.643413Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T14:37:28.168431Z",
     "iopub.status.busy": "2025-07-07T14:37:28.167749Z",
     "iopub.status.idle": "2025-07-07T14:37:28.174195Z",
     "shell.execute_reply": "2025-07-07T14:37:28.173381Z",
     "shell.execute_reply.started": "2025-07-07T14:37:28.168401Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# !pip install tensorflow scikit-learn\n",
    "\n",
    "\"\"\"# Paths\"\"\"\n",
    "\n",
    "rpsense_train_path = '/kaggle/input/rpsense-dataset/train'\n",
    "rpsense_test_path = '/kaggle/input/rpsense-dataset/test'\n",
    "rpsense_validation_path = '/kaggle/input/rpsense-dataset/validation'\n",
    "\n",
    "classes = ['invalid', 'paper', 'rock', 'scissors']\n",
    "\n",
    "\"\"\"# Import libraries\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Conv2D, AveragePooling2D, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# Define the target image size and batch size\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "BATCH_SIZE = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T14:37:31.291317Z",
     "iopub.status.busy": "2025-07-07T14:37:31.290527Z",
     "iopub.status.idle": "2025-07-07T14:37:36.527542Z",
     "shell.execute_reply": "2025-07-07T14:37:36.526804Z",
     "shell.execute_reply.started": "2025-07-07T14:37:31.291292Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"# Data Augmentation\"\"\"\n",
    "\n",
    "# Data augmentation for training to improve model generalization\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,      \n",
    "    rotation_range=20,              # Random rotation\n",
    "    width_shift_range=0.2,          # Horizontal shift\n",
    "    height_shift_range=0.2,         # Vertical shift\n",
    "    shear_range=0.2,                # Shearing transformation\n",
    "    zoom_range=0.2,                 # Zoom in/out\n",
    "    horizontal_flip=True,           # Random horizontal flip\n",
    "    fill_mode='nearest'             # Fill pixels after transformations\n",
    ")\n",
    "\n",
    "# For validation and testing: only normalize\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "validation_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "# Show some augmented images\n",
    "x_batch, y_batch = next(\n",
    "    train_datagen.flow_from_directory(\n",
    "        rpsense_train_path,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=16\n",
    "    )\n",
    ")\n",
    "# Plot 8 images from the batch\n",
    "for i in range(8):\n",
    "    plt.subplot(2, 4, i + 1)\n",
    "    plt.imshow(x_batch[i])\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-07-07T14:45:55.475950Z",
     "iopub.status.busy": "2025-07-07T14:45:55.475327Z",
     "iopub.status.idle": "2025-07-07T14:46:03.105822Z",
     "shell.execute_reply": "2025-07-07T14:46:03.105215Z",
     "shell.execute_reply.started": "2025-07-07T14:45:55.475927Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# \"\"\"Try connecting to TPU\"\"\"\n",
    "\n",
    "# try:\n",
    "#     tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
    "#     tf.config.experimental_connect_to_cluster(tpu)\n",
    "#     tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "#     strategy = tf.distribute.TPUStrategy(tpu)\n",
    "#     print(\"‚úÖ Connected to TPU\")\n",
    "# except ValueError:\n",
    "#     strategy = tf.distribute.get_strategy()  # Default strategy for CPU/GPU\n",
    "#     print(\"‚ö†Ô∏è TPU not found, using\", strategy)\n",
    "\n",
    "\"\"\"\n",
    "Try using GPU\n",
    "\n",
    "\"\"\"\n",
    "# Encountered NAN when using mirrored stratergy so shifting to 1 GPU only\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    print(\"‚úÖ GPU detected:\", physical_devices[0].name)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No GPU found, using CPU\")\n",
    "\n",
    "strategy = tf.distribute.get_strategy()  # Automatically detects and uses GPU\n",
    "\n",
    "print(\"‚úÖ Using strategy:\", strategy)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"# Load dataset\"\"\"\n",
    "\n",
    "# Load the training dataset\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    rpsense_train_path,             # Path to training data\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),  # Resize all images\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',       # For multi-class classification\n",
    "    classes=classes,                 # Define class order manually\n",
    "    # shuffle=True                    # Shuffle data for each epoch\n",
    ")\n",
    "\n",
    "# Load the validation dataset\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    rpsense_validation_path,        # Path to validation data\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    classes=classes,\n",
    "    # shuffle=False\n",
    ")\n",
    "\n",
    "# Load the test dataset\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    rpsense_test_path,              # Path to test data\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    classes=classes\n",
    ")\n",
    "\n",
    "\"\"\"compile in stratergy\"\"\"\n",
    "\n",
    "with strategy.scope():\n",
    "    base_model = MobileNetV2(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(IMG_HEIGHT, IMG_WIDTH, 3),\n",
    "    )\n",
    "    \n",
    "    base_model.trainable = False\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    predictions = Dense(len(classes), activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    optimizer = Adam(\n",
    "        learning_rate=0.0001,\n",
    "        clipnorm=1.0,  # Clip gradients by norm\n",
    "    )\n",
    "    \n",
    "    model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    "    )\n",
    "model.summary()\n",
    "\n",
    "\"\"\"# Configure Early Stopping and ModelCheckpoint\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',       # Or 'val_accuracy'\n",
    "    patience=5,               # Stop if no improvement after 5 epochs\n",
    "    restore_best_weights=True  # Load best model weights at end\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'best_mobilenetv2_rpsense_model.h5',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "# Reduce learning rate when validation loss plateaus\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T14:38:54.074697Z",
     "iopub.status.busy": "2025-07-07T14:38:54.074017Z",
     "iopub.status.idle": "2025-07-07T14:38:54.079098Z",
     "shell.execute_reply": "2025-07-07T14:38:54.078396Z",
     "shell.execute_reply.started": "2025-07-07T14:38:54.074673Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "len(model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-07-07T14:47:05.224936Z",
     "iopub.status.busy": "2025-07-07T14:47:05.224208Z",
     "iopub.status.idle": "2025-07-07T14:47:09.872682Z",
     "shell.execute_reply": "2025-07-07T14:47:09.871929Z",
     "shell.execute_reply.started": "2025-07-07T14:47:05.224912Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# a custom callback to monitor for NaN values during training\n",
    "class NaNMonitor(tf.keras.callbacks.Callback):\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        if logs is not None:\n",
    "            if np.isnan(logs.get('loss', 0)) or np.isnan(logs.get('accuracy', 0)):\n",
    "                print(f\"\\n‚ö†Ô∏è NaN detected at batch {batch}!\")\n",
    "                print(f\"Loss: {logs.get('loss')}, Accuracy: {logs.get('accuracy')}\")\n",
    "                self.model.stop_training = True\n",
    "\n",
    "# Create NaN monitor callback\n",
    "nan_monitor = NaNMonitor()\n",
    "\n",
    "# Also add a custom callback to check model weights\n",
    "class WeightMonitor(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Check if any weights are NaN\n",
    "        for layer in self.model.layers:\n",
    "            if hasattr(layer, 'weights') and layer.weights:\n",
    "                for weight in layer.weights:\n",
    "                    if tf.reduce_any(tf.math.is_nan(weight)):\n",
    "                        print(f\"\\n‚ö†Ô∏è NaN weights detected in layer {layer.name} at epoch {epoch}\")\n",
    "                        self.model.stop_training = True\n",
    "                        return\n",
    "\n",
    "weight_monitor = WeightMonitor()\n",
    "\n",
    "# Debug: Check model weights before training\n",
    "print(\"Checking initial model weights...\")\n",
    "for layer in model.layers[-3:]:  # Check last 3 layers\n",
    "    if hasattr(layer, 'weights') and layer.weights:\n",
    "        for i, weight in enumerate(layer.weights):\n",
    "            weight_values = weight.numpy()\n",
    "            print(f\"Layer {layer.name} weight {i}: shape={weight_values.shape}, \"\n",
    "                  f\"min={weight_values.min():.6f}, max={weight_values.max():.6f}, \"\n",
    "                  f\"mean={weight_values.mean():.6f}, has_nan={np.isnan(weight_values).any()}\")\n",
    "\n",
    "# Reset the generators to ensure clean state\n",
    "train_generator.reset()\n",
    "validation_generator.reset()\n",
    "\n",
    "# Debug: Check for NaN values in data before training\n",
    "print(\"Checking data for NaN values...\")\n",
    "x_batch, y_batch = next(train_generator)\n",
    "print(f\"Training batch shape: {x_batch.shape}\")\n",
    "print(f\"Training batch min/max: {x_batch.min():.4f} / {x_batch.max():.4f}\")\n",
    "print(f\"Training batch has NaN: {np.isnan(x_batch).any()}\")\n",
    "print(f\"Training labels shape: {y_batch.shape}\")\n",
    "print(f\"Training labels has NaN: {np.isnan(y_batch).any()}\")\n",
    "\n",
    "x_val_batch, y_val_batch = next(validation_generator)\n",
    "print(f\"Validation batch shape: {x_val_batch.shape}\")\n",
    "print(f\"Validation batch min/max: {x_val_batch.min():.4f} / {x_val_batch.max():.4f}\")\n",
    "print(f\"Validation batch has NaN: {np.isnan(x_val_batch).any()}\")\n",
    "print(f\"Validation labels has NaN: {np.isnan(y_val_batch).any()}\")\n",
    "\n",
    "# Reset generators again after debugging\n",
    "train_generator.reset()\n",
    "validation_generator.reset()\n",
    "\n",
    "# Try a test forward pass to check for NaN\n",
    "print(\"Testing forward pass...\")\n",
    "test_prediction = model.predict(x_batch[:1], verbose=0)\n",
    "print(f\"Test prediction shape: {test_prediction.shape}\")\n",
    "print(f\"Test prediction has NaN: {np.isnan(test_prediction).any()}\")\n",
    "print(f\"Test prediction values: {test_prediction[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-07-07T14:47:16.293994Z",
     "iopub.status.busy": "2025-07-07T14:47:16.293137Z",
     "iopub.status.idle": "2025-07-07T18:29:34.881668Z",
     "shell.execute_reply": "2025-07-07T18:29:34.880829Z",
     "shell.execute_reply.started": "2025-07-07T14:47:16.293969Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Train the model using the training and validation data\n",
    "\n",
    "EPOCHS = 50\n",
    "# Train using only 1000 images for each class.\n",
    "# train_steps = 1000 // BATCH_SIZE\n",
    "# val_steps = 300 // BATCH_SIZE\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[early_stop, checkpoint, reduce_lr, nan_monitor, weight_monitor],\n",
    "    verbose=1\n",
    "    # validation_steps=val_steps,\n",
    "    # steps_per_epoch=train_steps\n",
    ")\n",
    "\n",
    "model_save_path = '/kaggle/working/mobilenetv2_rpsense.h5'\n",
    "# Save the trained model to disk\n",
    "model.save(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T18:52:54.237930Z",
     "iopub.status.busy": "2025-07-07T18:52:54.237647Z",
     "iopub.status.idle": "2025-07-07T18:53:00.625448Z",
     "shell.execute_reply": "2025-07-07T18:53:00.624846Z",
     "shell.execute_reply.started": "2025-07-07T18:52:54.237910Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"# Evaluate on Test set\"\"\"\n",
    "\n",
    "# Evaluate the trained model on the test dataset\n",
    "test_loss, test_acc = model.evaluate(test_eval_generator)\n",
    "print(f\"‚úÖ Test Accuracy: {test_acc:.4f}, Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "# Plot Accuracy\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot Loss\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T18:58:56.170793Z",
     "iopub.status.busy": "2025-07-07T18:58:56.170424Z",
     "iopub.status.idle": "2025-07-07T19:03:29.856285Z",
     "shell.execute_reply": "2025-07-07T19:03:29.855714Z",
     "shell.execute_reply.started": "2025-07-07T18:58:56.170766Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_eval_generator = train_datagen.flow_from_directory(\n",
    "    rpsense_train_path,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    classes=classes,\n",
    "    shuffle=False  \n",
    ")\n",
    "\n",
    "# Load the test dataset\n",
    "test_eval_generator = test_datagen.flow_from_directory(\n",
    "    rpsense_test_path,              # Path to test data\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    classes=classes,\n",
    "    shuffle=False  \n",
    ")\n",
    "\n",
    "# Get true labels\n",
    "y_true = test_eval_generator.classes\n",
    "\n",
    "# Get predicted labels\n",
    "y_pred_probs = model.predict(test_eval_generator)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# Class names from the generator\n",
    "class_names = list(test_eval_generator.class_indices.keys())\n",
    "\n",
    "# Confusion Matrix for Test dataset\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Confusion Matrix - Test Data')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n",
    "\n",
    "# Confusion Matrix for Train dataset\n",
    "y_train_true = train_eval_generator.classes\n",
    "y_train_pred = np.argmax(model.predict(train_eval_generator), axis=1)\n",
    "\n",
    "cm_train = confusion_matrix(y_train_true, y_train_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_train, annot=True, fmt='d', cmap='Greens',\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Confusion Matrix - Train Data')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n",
    "\n",
    "print(\"Classification Report (Test):\")\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "\n",
    "print(\"Classification Report (Train):\")\n",
    "print(classification_report(y_train_true, y_train_pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T19:03:33.146380Z",
     "iopub.status.busy": "2025-07-07T19:03:33.146096Z",
     "iopub.status.idle": "2025-07-07T19:08:00.157297Z",
     "shell.execute_reply": "2025-07-07T19:08:00.156758Z",
     "shell.execute_reply.started": "2025-07-07T19:03:33.146359Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Evaluate the trained model on the train dataset\n",
    "train_loss, train_acc = model.evaluate(train_eval_generator)\n",
    "print(f\"‚úÖ Train Accuracy: {train_acc:.4f}, Train Loss: {train_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T18:57:39.373868Z",
     "iopub.status.busy": "2025-07-07T18:57:39.373196Z",
     "iopub.status.idle": "2025-07-07T18:57:39.379298Z",
     "shell.execute_reply": "2025-07-07T18:57:39.378609Z",
     "shell.execute_reply.started": "2025-07-07T18:57:39.373843Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(train_generator.class_indices)\n",
    "print(test_generator.class_indices)\n",
    "# Class names from the generator\n",
    "class_names = list(test_generator.class_indices.keys())\n",
    "class_names\n",
    "\n",
    "# there was mismatch between true and predicted labels, bcoz shuffle = True by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T19:08:30.080528Z",
     "iopub.status.busy": "2025-07-07T19:08:30.079965Z",
     "iopub.status.idle": "2025-07-07T19:08:30.084112Z",
     "shell.execute_reply": "2025-07-07T19:08:30.083509Z",
     "shell.execute_reply.started": "2025-07-07T19:08:30.080504Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('history.pkl', 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T19:12:38.681782Z",
     "iopub.status.busy": "2025-07-07T19:12:38.681509Z",
     "iopub.status.idle": "2025-07-07T19:12:51.004208Z",
     "shell.execute_reply": "2025-07-07T19:12:51.003597Z",
     "shell.execute_reply.started": "2025-07-07T19:12:38.681761Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('/kaggle/working/mobilenetv2_rpsense.h5')\n",
    "\n",
    "for i, layer in enumerate(model.layers):\n",
    "    print(i, layer.name, layer.trainable)\n",
    "\n",
    "# Evaluate the trained model on the test dataset\n",
    "test_loss, test_acc = model.evaluate(test_eval_generator)\n",
    "print(f\"‚úÖ Test Accuracy: {test_acc:.4f}, Test Loss: {test_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for layer in model.layers[:100]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[100:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-5),  # Smaller LR for fine-tuning\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,  # or new train_eval_generator if you want shuffle=False\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[early_stop, checkpoint]  # if you want\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T04:49:02.163313Z",
     "iopub.status.busy": "2025-07-08T04:49:02.162985Z",
     "iopub.status.idle": "2025-07-08T06:18:28.435617Z",
     "shell.execute_reply": "2025-07-08T06:18:28.434779Z",
     "shell.execute_reply.started": "2025-07-08T04:49:02.163276Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Fine-tuning script for RPS Classification Model\n",
    "# This script loads the pre-trained model and performs fine-tuning of layers after 100\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "\n",
    "# Paths and constants\n",
    "rpsense_train_path = '/kaggle/input/rpsense-dataset/train'\n",
    "rpsense_test_path = '/kaggle/input/rpsense-dataset/test'\n",
    "rpsense_validation_path = '/kaggle/input/rpsense-dataset/validation'\n",
    "model_path = '/kaggle/input/rpsensemobilenetv2/keras/default/1/mobilenetv2_rpsense.h5'\n",
    "\n",
    "classes = ['invalid', 'paper', 'rock', 'scissors']\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Set up strategy for GPU/TPU\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    print(\"‚úÖ GPU detected:\", physical_devices[0].name)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No GPU found, using CPU\")\n",
    "\n",
    "strategy = tf.distribute.get_strategy()\n",
    "print(\"‚úÖ Using strategy:\", strategy)\n",
    "\n",
    "# Data augmentation for training to improve model generalization\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,      \n",
    "    rotation_range=15,              # Reduced from 20 to prevent overfitting\n",
    "    width_shift_range=0.1,          # Reduced from 0.2\n",
    "    height_shift_range=0.1,         # Reduced from 0.2\n",
    "    shear_range=0.1,                # Reduced from 0.2\n",
    "    zoom_range=0.1,                 # Reduced from 0.2\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.8, 1.2],    # Add brightness variation\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# For validation and testing: only normalize\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "validation_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "# Load datasets\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    rpsense_train_path,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    classes=classes,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    rpsense_validation_path,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    classes=classes,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    rpsense_test_path,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    classes=classes,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "with strategy.scope():\n",
    "    # Load the pre-trained model\n",
    "    print(\"Loading pre-trained model...\")\n",
    "    model = load_model(model_path)\n",
    "    print(\"‚úÖ Model loaded successfully\")\n",
    "    \n",
    "    # Print model summary to understand the architecture\n",
    "    print(f\"Total layers in model: {len(model.layers)}\")\n",
    "    for i, layer in enumerate(model.layers):\n",
    "        print(f\"Layer {i}: {layer.name} - Trainable: {layer.trainable}\")\n",
    "    \n",
    "    # Freeze early layers, unfreeze later layers for fine-tuning\n",
    "    # You can adjust these numbers based on your model architecture\n",
    "    freeze_until = 100  # Freeze first 100 layers\n",
    "    \n",
    "    for i, layer in enumerate(model.layers):\n",
    "        if i < freeze_until:\n",
    "            layer.trainable = False\n",
    "        else:\n",
    "            layer.trainable = True\n",
    "    \n",
    "    print(f\"‚úÖ Layers 0-{freeze_until-1} frozen, layers {freeze_until}+ unfrozen\")\n",
    "    \n",
    "    # Count trainable parameters\n",
    "    trainable_params = sum([np.prod(layer.trainable_weights[0].shape) for layer in model.layers if layer.trainable_weights])\n",
    "    print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "    optimizer = Adam(\n",
    "        learning_rate=1e-5,\n",
    "        clipnorm=1.0,  # Clip gradients by norm\n",
    "    )\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "# Setup callbacks\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'best_finetuned_mobilenetv2_rpsense_model.h5',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Training parameters\n",
    "FINETUNE_EPOCHS = 20\n",
    "\n",
    "print(f\"\\nüî• Starting fine-tuning for {FINETUNE_EPOCHS} epochs...\")\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=FINETUNE_EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[early_stop, checkpoint, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Save the fine-tuned model\n",
    "finetuned_model_path = '/kaggle/working/finetuned_after100layers_mobilenetv2_rpsense.h5'\n",
    "model.save(finetuned_model_path)\n",
    "print(f\"‚úÖ Fine-tuned model saved to: {finetuned_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T06:20:42.395091Z",
     "iopub.status.busy": "2025-07-08T06:20:42.394804Z",
     "iopub.status.idle": "2025-07-08T06:20:42.399402Z",
     "shell.execute_reply": "2025-07-08T06:20:42.398725Z",
     "shell.execute_reply.started": "2025-07-08T06:20:42.395068Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('finetune_history.pkl', 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tune evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T06:20:49.805635Z",
     "iopub.status.busy": "2025-07-08T06:20:49.804812Z",
     "iopub.status.idle": "2025-07-08T06:21:15.671361Z",
     "shell.execute_reply": "2025-07-08T06:21:15.670729Z",
     "shell.execute_reply.started": "2025-07-08T06:20:49.805599Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"\\nüìä Evaluating fine-tuned model on test set...\")\n",
    "test_loss, test_acc = model.evaluate(test_generator, verbose=1)\n",
    "print(f\"‚úÖ Fine-tuned Test Accuracy: {test_acc:.4f}, Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "# Plot Accuracy\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot Loss\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Generate predictions and confusion matrix\n",
    "print(\"\\nüîç Generating predictions and confusion matrix...\")\n",
    "test_generator.reset()\n",
    "predictions = model.predict(test_generator)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = test_generator.classes\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(true_classes, predicted_classes)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=classes, yticklabels=classes)\n",
    "plt.title('Confusion Matrix - Fine-tuned Model')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nüìã Classification Report:\")\n",
    "print(classification_report(true_classes, predicted_classes, target_names=classes))\n",
    "\n",
    "# Compare with original model performance\n",
    "print(\"\\nüìà Performance Comparison:\")\n",
    "print(\"Original Model - Test Accuracy: ~89%\")\n",
    "print(f\"Fine-tuned Model - Test Accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
    "\n",
    "improvement = (test_acc - 0.89) * 100\n",
    "if improvement > 0:\n",
    "    print(f\"‚úÖ Improvement: +{improvement:.2f}%\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Change: {improvement:.2f}%\")\n",
    "\n",
    "print(\"\\nüéØ Fine-tuning completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T06:30:34.889268Z",
     "iopub.status.busy": "2025-07-08T06:30:34.888694Z",
     "iopub.status.idle": "2025-07-08T06:30:35.083083Z",
     "shell.execute_reply": "2025-07-08T06:30:35.082371Z",
     "shell.execute_reply.started": "2025-07-08T06:30:34.889243Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_eval_generator = train_datagen.flow_from_directory(\n",
    "    rpsense_train_path,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    classes=classes,\n",
    "    shuffle=False  \n",
    ")\n",
    "\n",
    "class_names = list(train_eval_generator.class_indices.keys())\n",
    "\n",
    "# Confusion Matrix for Train dataset\n",
    "y_train_true = train_eval_generator.classes\n",
    "y_train_pred = np.argmax(model.predict(train_eval_generator), axis=1)\n",
    "\n",
    "cm_train = confusion_matrix(y_train_true, y_train_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_train, annot=True, fmt='d', cmap='Greens',\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Confusion Matrix - Train Data')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n",
    "\n",
    "print(\"Classification Report (Train):\")\n",
    "print(classification_report(y_train_true, y_train_pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T06:30:46.551501Z",
     "iopub.status.busy": "2025-07-08T06:30:46.550923Z",
     "iopub.status.idle": "2025-07-08T06:35:41.231072Z",
     "shell.execute_reply": "2025-07-08T06:35:41.230487Z",
     "shell.execute_reply.started": "2025-07-08T06:30:46.551476Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Evaluate the trained model on the train dataset\n",
    "train_loss, train_acc = model.evaluate(train_eval_generator)\n",
    "print(f\"‚úÖ Train Accuracy: {train_acc:.4f}, Train Loss: {train_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T06:39:52.565608Z",
     "iopub.status.busy": "2025-07-08T06:39:52.565071Z",
     "iopub.status.idle": "2025-07-08T06:40:04.321642Z",
     "shell.execute_reply": "2025-07-08T06:40:04.320877Z",
     "shell.execute_reply.started": "2025-07-08T06:39:52.565584Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Evaluate the trained model on the train dataset\n",
    "valid_loss, valid_acc = model.evaluate(validation_generator)\n",
    "print(f\"‚úÖ Valid Accuracy: {valid_acc:.4f}, Valid Loss: {valid_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-07-08T06:36:37.932976Z",
     "iopub.status.busy": "2025-07-08T06:36:37.932696Z",
     "iopub.status.idle": "2025-07-08T06:36:50.782822Z",
     "shell.execute_reply": "2025-07-08T06:36:50.781941Z",
     "shell.execute_reply.started": "2025-07-08T06:36:37.932955Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Export model in TensorFlow SavedModel format (for TF Serving, TFLite, etc.)\n",
    "saved_model_dir = '/kaggle/working/finetuned_after100layers_mobilenetv2_rpsense_savedmodel'\n",
    "model.export(saved_model_dir)\n",
    "\n",
    "print(f\"‚úÖ Exported model saved to: {saved_model_dir}\")\n",
    "\n",
    "import shutil\n",
    "\n",
    "# Define zip path\n",
    "zip_path = '/kaggle/working/finetuned_after100layers_mobilenetv2_rpsense_savedmodel.zip'\n",
    "\n",
    "# Zip the exported model folder\n",
    "shutil.make_archive(zip_path.replace('.zip', ''), 'zip', saved_model_dir)\n",
    "\n",
    "print(f\"‚úÖ Zipped exported model: {zip_path}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7818577,
     "sourceId": 12398447,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 395287,
     "modelInstanceId": 374419,
     "sourceId": 463386,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 395289,
     "modelInstanceId": 374422,
     "sourceId": 463390,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
