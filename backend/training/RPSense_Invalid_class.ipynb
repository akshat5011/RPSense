{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0RZbRe-8-5AW"
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/datasets/deeppythonist/american-sign-language-dataset\n",
    "\n",
    "# https://www.kaggle.com/datasets/vaishnaviasonawane/indian-sign-language-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 253,
     "status": "ok",
     "timestamp": 1751799162442,
     "user": {
      "displayName": "Akshat",
      "userId": "02656238651709843440"
     },
     "user_tz": -330
    },
    "id": "qu5t10FbLtr_",
    "outputId": "85982041-a437-4f74-8f67-16fde98feb54"
   },
   "outputs": [],
   "source": [
    "!mkdir dataset\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7UOrD8LLR_tO"
   },
   "source": [
    "# American Sign Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6969,
     "status": "ok",
     "timestamp": 1751799172636,
     "user": {
      "displayName": "Akshat",
      "userId": "02656238651709843440"
     },
     "user_tz": -330
    },
    "id": "mS-0PpPX-8j9",
    "outputId": "db81667f-b6c7-42f6-a25d-afde75ca814e"
   },
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"deeppythonist/american-sign-language-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mbRMkgQCMJ0S"
   },
   "outputs": [],
   "source": [
    "# ASL Letters: A e , M, N, S t as rock\n",
    "# ASL Letters:   5 as paper\n",
    "# ASL Letters: V, 2 k u h as scissors\n",
    "# invalid 0 1 3 4 6 7 8 9 b c d f g i j l o p q r w x y z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 879,
     "status": "ok",
     "timestamp": 1751796607720,
     "user": {
      "displayName": "Akshat",
      "userId": "02656238651709843440"
     },
     "user_tz": -330
    },
    "id": "rWpltAncNHnv",
    "outputId": "f70848dd-0a05-4953-b70d-2138536a8b58"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import Image, display\n",
    "\n",
    "base_path = '/kaggle/input/american-sign-language-dataset/ASL_Gestures_36_Classes/test'\n",
    "\n",
    "# List of subfolders (0-9, a-z)\n",
    "subfolders = [str(i) for i in range(10)] + [chr(ord('a') + i) for i in range(26)]\n",
    "\n",
    "for folder_name in subfolders:\n",
    "    folder_path = os.path.join(base_path, folder_name)\n",
    "    if os.path.exists(folder_path) and os.path.isdir(folder_path):\n",
    "        # List files in the subfolder\n",
    "        files = os.listdir(folder_path)\n",
    "        # Filter for image files (you might want to add more extensions)\n",
    "        image_files = [f for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))]\n",
    "\n",
    "        if image_files:\n",
    "            # Take the first image found\n",
    "            sample_image_path = os.path.join(folder_path, image_files[0])\n",
    "            print(f\"Displaying image from subfolder: {folder_name}\")\n",
    "            display(Image(filename=sample_image_path))\n",
    "        else:\n",
    "            print(f\"No image files found in subfolder: {folder_name}\")\n",
    "    else:\n",
    "        print(f\"Subfolder not found: {folder_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7071,
     "status": "ok",
     "timestamp": 1751799215350,
     "user": {
      "displayName": "Akshat",
      "userId": "02656238651709843440"
     },
     "user_tz": -330
    },
    "id": "QRm30woeNOwA",
    "outputId": "65255c85-6e08-44e6-dd20-352d628a8fd5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "base_path = '/kaggle/input/american-sign-language-dataset/ASL_Gestures_36_Classes'\n",
    "\n",
    "# List of subfolders (0-9, a-z)\n",
    "subfolders = [str(i) for i in range(10)] + [chr(ord('a') + i) for i in range(26)]\n",
    "\n",
    "# Segregation logic\n",
    "rock_letters = ['a', 'e', 'm', 'n', 's', 't']\n",
    "paper_letters = ['5']\n",
    "scissors_letters = ['v', '2', 'k', 'u', 'h']\n",
    "invalid_letters = ['0', '1', '3', '4', '6', '7', '8', '9',\n",
    "                   'b', 'c', 'd', 'f', 'g', 'i', 'j',\n",
    "                   'l', 'o', 'p', 'q', 'r', 'w', 'x', 'y', 'z']\n",
    "\n",
    "output_base_path = '/content/dataset/'\n",
    "rock_output_path = os.path.join(output_base_path, 'rock')\n",
    "paper_output_path = os.path.join(output_base_path, 'paper')\n",
    "scissors_output_path = os.path.join(output_base_path, 'scissors')\n",
    "invalid_output_path = os.path.join(output_base_path, 'invalid')\n",
    "\n",
    "# Create output directories if they don't exist\n",
    "os.makedirs(rock_output_path, exist_ok=True)\n",
    "os.makedirs(paper_output_path, exist_ok=True)\n",
    "os.makedirs(scissors_output_path, exist_ok=True)\n",
    "os.makedirs(invalid_output_path, exist_ok=True)\n",
    "\n",
    "# Loop through 'train' and 'test' folders\n",
    "for split in ['train', 'test']:\n",
    "    split_path = os.path.join(base_path, split)\n",
    "\n",
    "    if not os.path.exists(split_path):\n",
    "        print(f\"Split folder not found: {split_path}\")\n",
    "        continue\n",
    "\n",
    "    for folder_name in subfolders:\n",
    "        folder_path = os.path.join(split_path, folder_name)\n",
    "        if os.path.exists(folder_path) and os.path.isdir(folder_path):\n",
    "            files = os.listdir(folder_path)\n",
    "            image_files = [f for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "            target_folder = None\n",
    "            # Determine the target folder based on the letter/number\n",
    "            if folder_name in rock_letters:\n",
    "                target_folder = rock_output_path\n",
    "            elif folder_name in paper_letters:\n",
    "                target_folder = paper_output_path\n",
    "            elif folder_name in scissors_letters:\n",
    "                target_folder = scissors_output_path\n",
    "            elif folder_name in invalid_letters:\n",
    "                target_folder = invalid_output_path\n",
    "\n",
    "            if target_folder:\n",
    "                for image_file in image_files:\n",
    "                    source_path = os.path.join(folder_path, image_file)\n",
    "                    # Prefix with train/ or test/ to avoid filename collisions\n",
    "                    destination_filename = f\"{split}_{folder_name}_{image_file}\"\n",
    "                    destination_path = os.path.join(target_folder, destination_filename)\n",
    "                    shutil.copy(source_path, destination_path)\n",
    "                print(f\"Copied images from '{split}/{folder_name}' to '{target_folder}'\")\n",
    "            else:\n",
    "                print(f\"Folder '{folder_name}' does not match any known category. Skipping.\")\n",
    "        else:\n",
    "            print(f\"Source subfolder not found: {folder_path}\")\n",
    "\n",
    "print(\"Segregation complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "khQNsTfnR3KT"
   },
   "source": [
    "ASL dataset segregation completed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YhG586MBR7RI"
   },
   "source": [
    "# Indian Sign Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4404,
     "status": "ok",
     "timestamp": 1751799229925,
     "user": {
      "displayName": "Akshat",
      "userId": "02656238651709843440"
     },
     "user_tz": -330
    },
    "id": "B6xIveO8R-aA",
    "outputId": "8d224efb-0441-4c87-f51b-2e2e4381ead8"
   },
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"vaishnaviasonawane/indian-sign-language-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 2118,
     "status": "ok",
     "timestamp": 1751797933390,
     "user": {
      "displayName": "Akshat",
      "userId": "02656238651709843440"
     },
     "user_tz": -330
    },
    "id": "M4P0-H7nSJO2",
    "outputId": "3f1702c2-5a07-46b8-e69b-23231c0a2525"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import Image, display\n",
    "\n",
    "base_path = path + '/data'\n",
    "# List of subfolders (0-9, a-z)\n",
    "subfolders = [str(i) for i in range(1,10)] + [chr(ord('A') + i) for i in range(26)]\n",
    "\n",
    "for folder_name in subfolders:\n",
    "    folder_path = os.path.join(base_path, folder_name)\n",
    "    if os.path.exists(folder_path) and os.path.isdir(folder_path):\n",
    "        # List files in the subfolder\n",
    "        files = os.listdir(folder_path)\n",
    "        # Filter for image files (you might want to add more extensions)\n",
    "        image_files = [f for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))]\n",
    "\n",
    "        if image_files:\n",
    "            # Take the first image found\n",
    "            sample_image_path = os.path.join(folder_path, image_files[0])\n",
    "            print(f\"Displaying image from subfolder: {folder_name}\")\n",
    "            display(Image(filename=sample_image_path))\n",
    "        else:\n",
    "            print(f\"No image files found in subfolder: {folder_name}\")\n",
    "    else:\n",
    "        print(f\"Subfolder not found: {folder_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 67,
     "status": "ok",
     "timestamp": 1751799237348,
     "user": {
      "displayName": "Akshat",
      "userId": "02656238651709843440"
     },
     "user_tz": -330
    },
    "id": "bvcSEwO-S_2x",
    "outputId": "c8585481-4a7d-4f18-d589-c9616832e86a"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Load the image\n",
    "image_path = '/kaggle/input/indian-sign-language-dataset/data/1/0.jpg'\n",
    "with Image.open(image_path) as img:\n",
    "    print(f\"Image size: {img.size}\")  # Output will be (width, height)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CgsPKaxTVk49"
   },
   "outputs": [],
   "source": [
    "# rock - G\n",
    "# paper - 5\n",
    "# scissor V 2\n",
    "# invalid rest all\n",
    "\n",
    "# 1-9   A-Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12090,
     "status": "ok",
     "timestamp": 1751799261686,
     "user": {
      "displayName": "Akshat",
      "userId": "02656238651709843440"
     },
     "user_tz": -330
    },
    "id": "V4-3KiJzV2aR",
    "outputId": "e012363c-2bc9-468b-8894-912ece0548f7"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Segregation logic for ISL\n",
    "isl_rock_letters = ['G']\n",
    "isl_paper_letters = ['5']\n",
    "isl_scissors_letters = ['V', '2']\n",
    "# Invalid ISL: 1-9 except 5,2,  A-Z except G, V\n",
    "isl_invalid_letters = [str(i) for i in range(1, 10) if str(i) not in isl_paper_letters + isl_scissors_letters] + \\\n",
    "                      [chr(ord('A') + i) for i in range(26) if chr(ord('A') + i) not in isl_rock_letters + isl_scissors_letters]\n",
    "\n",
    "# Ensure the output paths are created\n",
    "isl_output_base_path = '/content/dataset/'\n",
    "isl_rock_output_path = os.path.join(isl_output_base_path, 'rock')\n",
    "isl_paper_output_path = os.path.join(isl_output_base_path, 'paper')\n",
    "isl_scissors_output_path = os.path.join(isl_output_base_path, 'scissors')\n",
    "isl_invalid_output_path = os.path.join(isl_output_base_path, 'invalid')\n",
    "\n",
    "os.makedirs(isl_rock_output_path, exist_ok=True)\n",
    "os.makedirs(isl_paper_output_path, exist_ok=True)\n",
    "os.makedirs(isl_scissors_output_path, exist_ok=True)\n",
    "os.makedirs(isl_invalid_output_path, exist_ok=True)\n",
    "\n",
    "# Base path for the downloaded ISL dataset\n",
    "isl_base_path = path + '/data'\n",
    "\n",
    "# List of subfolders in the ISL dataset (1-9, A-Z)\n",
    "isl_subfolders = [str(i) for i in range(1, 10)] + [chr(ord('A') + i) for i in range(26)]\n",
    "\n",
    "# Loop through the subfolders of the ISL dataset\n",
    "if os.path.exists(isl_base_path) and os.path.isdir(isl_base_path):\n",
    "    for folder_name in isl_subfolders:\n",
    "        folder_path = os.path.join(isl_base_path, folder_name)\n",
    "\n",
    "        if os.path.exists(folder_path) and os.path.isdir(folder_path):\n",
    "            files = os.listdir(folder_path)\n",
    "            image_files = [f for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "            image_files = image_files[:100]  # Copy only the first 100 images\n",
    "\n",
    "            target_folder = None\n",
    "            # Determine the target folder based on the letter/number\n",
    "            if folder_name in isl_rock_letters:\n",
    "                target_folder = isl_rock_output_path\n",
    "            elif folder_name in isl_paper_letters:\n",
    "                target_folder = isl_paper_output_path\n",
    "            elif folder_name in isl_scissors_letters:\n",
    "                target_folder = isl_scissors_output_path\n",
    "            elif folder_name in isl_invalid_letters:\n",
    "                target_folder = isl_invalid_output_path\n",
    "            else:\n",
    "                print(f\"Folder '{folder_name}' from ISL dataset does not match any known category. Skipping.\")\n",
    "\n",
    "            if target_folder:\n",
    "                for image_file in image_files:\n",
    "                    source_path = os.path.join(folder_path, image_file)\n",
    "                    # Prefix with ISL_ to distinguish from ASL and avoid collisions\n",
    "                    destination_filename = f\"ISL_{folder_name}_{image_file}\"\n",
    "                    destination_path = os.path.join(target_folder, destination_filename)\n",
    "                    shutil.copy(source_path, destination_path)\n",
    "                print(f\"Copied up to 100 images from ISL '{folder_name}' to '{target_folder}'\")\n",
    "\n",
    "        else:\n",
    "            print(f\"ISL source subfolder not found: {folder_path}\")\n",
    "else:\n",
    "    print(f\"ISL base path not found: {isl_base_path}\")\n",
    "\n",
    "print(\"ISL Segregation complete.\")\n",
    "print(f\"Total rock images: {len(os.listdir(isl_rock_output_path))}\")\n",
    "print(f\"Total paper images: {len(os.listdir(isl_paper_output_path))}\")\n",
    "print(f\"Total scissors images: {len(os.listdir(isl_scissors_output_path))}\")\n",
    "print(f\"Total invalid images: {len(os.listdir(isl_invalid_output_path))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29316,
     "status": "ok",
     "timestamp": 1751806948085,
     "user": {
      "displayName": "Akshat",
      "userId": "02656238651709843440"
     },
     "user_tz": -330
    },
    "id": "nlWYDyeBX_ih",
    "outputId": "0506c38f-50da-48e0-b39b-bc7967ffa84e"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 747272,
     "status": "ok",
     "timestamp": 1751800306696,
     "user": {
      "displayName": "Akshat",
      "userId": "02656238651709843440"
     },
     "user_tz": -330
    },
    "id": "54cUTDxtYU7J",
    "outputId": "2da10361-4f92-4e18-a4be-50c51bde3850"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image, ImageFilter\n",
    "import shutil\n",
    "\n",
    "# Define the base path for the RPSense_Dataset\n",
    "rpsense_base_path = '/content/drive/MyDrive/RPSense_Dataset/dataset/train'\n",
    "\n",
    "# Define the output directory for invalid images\n",
    "output_invalid_path = '/content/dataset/invalid'\n",
    "os.makedirs(output_invalid_path, exist_ok=True)\n",
    "\n",
    "# List of folders corresponding to rock, paper, scissors\n",
    "rps_folders = ['rock', 'paper', 'scissors']\n",
    "\n",
    "num_images_to_select = 250\n",
    "\n",
    "print(\"Processing RPSense_Dataset for invalid class generation...\")\n",
    "\n",
    "for folder_name in rps_folders:\n",
    "    folder_path = os.path.join(rpsense_base_path, folder_name)\n",
    "\n",
    "    if os.path.exists(folder_path) and os.path.isdir(folder_path):\n",
    "        files = os.listdir(folder_path)\n",
    "        image_files = [f for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "        if not image_files:\n",
    "            print(f\"No image files found in {folder_path}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Select random images\n",
    "        selected_images = random.sample(image_files, min(num_images_to_select, len(image_files)))\n",
    "\n",
    "        print(f\"Selected {len(selected_images)} images from '{folder_name}' for blurring.\")\n",
    "\n",
    "        for image_file in selected_images:\n",
    "            source_path = os.path.join(folder_path, image_file)\n",
    "            try:\n",
    "                with Image.open(source_path) as img:\n",
    "                    # Convert to RGB if necessary (some operations might fail on paletted images)\n",
    "                    if img.mode != 'RGB':\n",
    "                        img = img.convert('RGB')\n",
    "\n",
    "                    # Apply a blur filter\n",
    "                    blurred_img = img.filter(ImageFilter.GaussianBlur(radius=5)) # Adjust radius as needed\n",
    "\n",
    "                    # Define the destination path for the blurred image\n",
    "                    # Prefix to avoid potential filename conflicts\n",
    "                    destination_filename = f\"RPSense_{folder_name}_{image_file}\"\n",
    "                    destination_path = os.path.join(output_invalid_path, destination_filename)\n",
    "\n",
    "                    # Save the blurred image\n",
    "                    blurred_img.save(destination_path)\n",
    "                    # print(f\"Blurred and saved {image_file} to {destination_path}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing image {source_path}: {e}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Source folder not found: {folder_path}\")\n",
    "\n",
    "print(\"RPSense_Dataset invalid class generation complete.\")\n",
    "print(f\"Total invalid images in {output_invalid_path}: {len(os.listdir(output_invalid_path))}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68620,
     "status": "ok",
     "timestamp": 1751800466819,
     "user": {
      "displayName": "Akshat",
      "userId": "02656238651709843440"
     },
     "user_tz": -330
    },
    "id": "JUNTCQtmZDOg",
    "outputId": "2632f22f-d02e-438f-86a8-49f457c26086"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Source base folder\n",
    "source_base_path = '/content/dataset'\n",
    "\n",
    "# Destination base folder on Google Drive\n",
    "dest_base_path = '/content/drive/MyDrive/RPSense_Dataset/dataset'\n",
    "\n",
    "# Subfolders and target split sizes\n",
    "subfolders = ['rock', 'paper', 'scissors', 'invalid']\n",
    "split_counts = {'train': 5100, 'test': 300}  # validation = rest\n",
    "\n",
    "# Ensure subfolders exist in destination folders, create 'invalid' folders if missing\n",
    "for split in ['train', 'test', 'validation']:\n",
    "    for subfolder in subfolders:\n",
    "        dest_subfolder_path = os.path.join(dest_base_path, split, subfolder)\n",
    "        os.makedirs(dest_subfolder_path, exist_ok=True)  # won't overwrite if it exists\n",
    "\n",
    "# Process each subfolder\n",
    "for subfolder in subfolders:\n",
    "    source_path = os.path.join(source_base_path, subfolder)\n",
    "\n",
    "    if not os.path.exists(source_path):\n",
    "        print(f\"Source subfolder not found: {source_path}\")\n",
    "        continue\n",
    "\n",
    "    image_files = [f for f in os.listdir(source_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    random.shuffle(image_files)  # Shuffle for random split\n",
    "\n",
    "    train_files = image_files[:split_counts['train']]\n",
    "    test_files = image_files[split_counts['train']:split_counts['train'] + split_counts['test']]\n",
    "    val_files = image_files[split_counts['train'] + split_counts['test']:]\n",
    "\n",
    "    split_map = {\n",
    "        'train': train_files,\n",
    "        'test': test_files,\n",
    "        'validation': val_files\n",
    "    }\n",
    "\n",
    "    for split_name, files in split_map.items():\n",
    "        for file_name in files:\n",
    "            src_file = os.path.join(source_path, file_name)\n",
    "            dest_file = os.path.join(dest_base_path, split_name, subfolder, file_name)\n",
    "\n",
    "            try:\n",
    "                shutil.copy(src_file, dest_file)\n",
    "            except Exception as e:\n",
    "                print(f\"Error copying {file_name} to {split_name}/{subfolder}: {e}\")\n",
    "\n",
    "    print(f\"Copied {len(train_files)} to train, {len(test_files)} to test, {len(val_files)} to validation for '{subfolder}'.\")\n",
    "\n",
    "print(\"Dataset split and copy complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3143,
     "status": "ok",
     "timestamp": 1751800574491,
     "user": {
      "displayName": "Akshat",
      "userId": "02656238651709843440"
     },
     "user_tz": -330
    },
    "id": "DYVbqMwgck6Q",
    "outputId": "824cfe32-23b4-4232-fe95-400bcebfcd14"
   },
   "outputs": [],
   "source": [
    "base_path = '/content/drive/MyDrive/RPSense_Dataset/dataset/'\n",
    "print(\"\\nChecking file extensions in  Gdrive:\")\n",
    "for root, dirs, files in os.walk(base_path):\n",
    "    if files:\n",
    "        print(f\"In directory: {root}\")\n",
    "        extensions = set()\n",
    "        for file in files:\n",
    "            _, ext = os.path.splitext(file)\n",
    "            extensions.add(ext.lower())\n",
    "        print(f\"  File extensions found: {list(extensions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 724,
     "status": "ok",
     "timestamp": 1751800617472,
     "user": {
      "displayName": "Akshat",
      "userId": "02656238651709843440"
     },
     "user_tz": -330
    },
    "id": "ZxiWy7Ycc7Yv",
    "outputId": "7aea00f3-f45a-4f67-9b9b-f28e879f1774"
   },
   "outputs": [],
   "source": [
    "base_path = '/content/drive/MyDrive/RPSense_Dataset/dataset/'\n",
    "subfolders = ['train', 'test', 'validation']\n",
    "classes = ['paper', 'rock', 'scissors', 'invalid']\n",
    "\n",
    "for subfolder in subfolders:\n",
    "    folder_path = os.path.join(base_path, subfolder)\n",
    "    print(f\"Files in {folder_path}:\")\n",
    "    if os.path.exists(folder_path):\n",
    "        for class_name in classes:\n",
    "            class_path = os.path.join(folder_path, class_name)\n",
    "            if os.path.exists(class_path):\n",
    "                num_files = len(os.listdir(class_path))\n",
    "                print(f\"  {class_name}: {num_files} files\")\n",
    "            else:\n",
    "                print(f\"  {class_name}: Folder not found\")\n",
    "    else:\n",
    "        print(\"  Folder not found\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A9nJ1qn_dOib"
   },
   "source": [
    "# 24,304 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9823,
     "status": "ok",
     "timestamp": 1751800646780,
     "user": {
      "displayName": "Akshat",
      "userId": "02656238651709843440"
     },
     "user_tz": -330
    },
    "id": "M1ICCKaTdF4Y",
    "outputId": "a4a47394-0d0c-4236-979b-4a58d570a9c8"
   },
   "outputs": [],
   "source": [
    "def get_dir_size_in_gb(directory_path):\n",
    "    \"\"\"Calculates the total size of a directory in gigabytes.\"\"\"\n",
    "    total_size = 0\n",
    "    if os.path.exists(directory_path):\n",
    "        for dirpath, dirnames, filenames in os.walk(directory_path):\n",
    "            for f in filenames:\n",
    "                fp = os.path.join(dirpath, f)\n",
    "                # skip if it is symbolic link\n",
    "                if not os.path.islink(fp):\n",
    "                    total_size += os.path.getsize(fp)\n",
    "        return total_size / (1024 * 1024 * 1024)  # Convert bytes to GB\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "dataset_size_gb = get_dir_size_in_gb(base_path)\n",
    "print(f\"Size of the dataset at {base_path}: {dataset_size_gb:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nq5yy2Ih1YFo"
   },
   "source": [
    "Move to validation from train for better split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 50532,
     "status": "ok",
     "timestamp": 1751807198815,
     "user": {
      "displayName": "Akshat",
      "userId": "02656238651709843440"
     },
     "user_tz": -330
    },
    "id": "jix8G5v21AUC",
    "outputId": "425aad18-6ff3-442f-bb99-42c2fee51723"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Define the source and destination paths\n",
    "source_train_folder = '/content/drive/MyDrive/RPSense_Dataset/dataset/train'\n",
    "destination_val_folder = '/content/drive/MyDrive/RPSense_Dataset/dataset/validation'\n",
    "\n",
    "# Number of images to move per class\n",
    "num_images_to_move = 500\n",
    "\n",
    "# List of classes (subfolders)\n",
    "classes = ['paper', 'rock', 'scissors', 'invalid']\n",
    "\n",
    "print(f\"Moving {num_images_to_move} images from each class in '{source_train_folder}' to '{destination_val_folder}'...\")\n",
    "\n",
    "for class_name in classes:\n",
    "    source_class_path = os.path.join(source_train_folder, class_name)\n",
    "    destination_class_path = os.path.join(destination_val_folder, class_name)\n",
    "\n",
    "    # List all files in the source class folder\n",
    "    all_files = os.listdir(source_class_path)\n",
    "    image_files = [f for f in all_files if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    if not image_files:\n",
    "        print(f\"No image files found in {source_class_path}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Select random images to move\n",
    "    # Ensure we don't try to move more images than are available\n",
    "    images_to_move = random.sample(image_files, min(num_images_to_move, len(image_files)))\n",
    "\n",
    "    print(f\"Selected {len(images_to_move)} images from '{class_name}' for moving to validation.\")\n",
    "\n",
    "    # Move the selected images\n",
    "    for image_file in images_to_move:\n",
    "        source_file_path = os.path.join(source_class_path, image_file)\n",
    "        destination_file_path = os.path.join(destination_class_path, image_file)\n",
    "\n",
    "        try:\n",
    "            shutil.move(source_file_path, destination_file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error moving {image_file} from '{class_name}': {e}\")\n",
    "\n",
    "print(\"\\nImage moving complete.\")\n",
    "\n",
    "# Verify the counts after moving\n",
    "print(\"\\nChecking counts after moving:\")\n",
    "base_path = '/content/drive/MyDrive/RPSense_Dataset/dataset/'\n",
    "subfolders = ['train', 'test', 'validation']\n",
    "classes = ['paper', 'rock', 'scissors', 'invalid']\n",
    "\n",
    "for subfolder in subfolders:\n",
    "    folder_path = os.path.join(base_path, subfolder)\n",
    "    print(f\"Files in {folder_path}:\")\n",
    "    if os.path.exists(folder_path):\n",
    "        for class_name in classes:\n",
    "            class_path = os.path.join(folder_path, class_name)\n",
    "            if os.path.exists(class_path):\n",
    "                num_files = len(os.listdir(class_path))\n",
    "                print(f\"  {class_name}: {num_files} files\")\n",
    "            else:\n",
    "                print(f\"  {class_name}: Folder not found\")\n",
    "    else:\n",
    "        print(\"  Folder not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oS4YfnZkdWQU"
   },
   "source": [
    "# Dataset Completed for training"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP/RJjEHArTajQX2g8fM4Ij",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
